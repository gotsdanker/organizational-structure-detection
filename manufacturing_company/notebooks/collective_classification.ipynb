{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from manufacturing_company.src.common.const import *\n",
    "from manufacturing_company.src.network.social_network import *\n",
    "from manufacturing_company.src.classification_algorithms.standard_classification import *\n",
    "from manufacturing_company.src.classification_algorithms.NodeInfo import NodeInfo\n",
    "from sklearn.metrics import jaccard_similarity_score, jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECTIVE CLASSIFICATION\n",
    "df_positions = pd.read_csv('manufacturing_company/data/raw/positions.csv', sep=';', comment='#', index_col=ID)\n",
    "\n",
    "for i in range(1, SIZE + 1):\n",
    "    df_features = pd.read_csv('manufacturing_company/data/intermediate/05_features/' + str(i) + '_months_features.csv', sep=';', index_col=ID)\n",
    "    \n",
    "    df_communication = pd.read_csv('manufacturing_company/data/intermediate/03_minimum_activity/' + str(i) + '_months_communication.csv', sep=';')\n",
    "    G = create_network(df_communication, weight=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_nodes_based_on_utility_score(utility_score_name, utility_score, pct, levels):  \n",
    "    utility_score = utility_score.sort_values(utility_score_name, ascending=False)\n",
    "\n",
    "    known_nodes_map = dict()\n",
    "    \n",
    "    for position in range(1, levels + 1):\n",
    "        employees_on_given_position = utility_score[utility_score[POSITION] == position]\n",
    "        all_nodes = len(employees_on_given_position)\n",
    "        known_nodes = round(all_nodes * pct)\n",
    "        \n",
    "        known_nodes_id = employees_on_given_position.iloc[:known_nodes].index\n",
    "        known_nodes_map.update({id: position for id in known_nodes_id})\n",
    "        \n",
    "    return known_nodes_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_passing(G, known_nodes, threshold, minority_labels): \n",
    "    df_nodes = pd.DataFrame(G.nodes(data='utility_score'), columns=[ID, 'utility_score'])\n",
    "    df_nodes = df_nodes.set_index(ID)\n",
    "    \n",
    "    order_desc = df_nodes.sort_values('utility_score', ascending=True).index\n",
    "    \n",
    "    nodes = pd.DataFrame(G.nodes(data='label'), columns=[ID, 'label'])\n",
    "    nodes = nodes.set_index(ID)\n",
    "    nodes = nodes.loc[order_desc, 'label'].to_dict()\n",
    "    # print(nodes)\n",
    "    label_counter = {node_id: NodeInfo() for node_id in nodes.keys()}\n",
    "    \n",
    "    G = G.to_undirected()\n",
    "    \n",
    "    end = False\n",
    "    \n",
    "    while not end:\n",
    "        old_labels = [value for (key, value) in nodes.items() if key not in known_nodes]\n",
    "        for node, label in nodes.items():\n",
    "            if label != -1:\n",
    "                neighbors = G.neighbors(node)\n",
    "                for neighbor in neighbors:\n",
    "                    if neighbor not in known_nodes:\n",
    "                        label_counter[neighbor].labels.append(label)\n",
    "        \n",
    "        # UPDATE LABELS\n",
    "        for node, label in nodes.items():\n",
    "            unique_labels = len(set(label_counter[node].labels)) == 1\n",
    "\n",
    "            # TODO method calculate label frequency\n",
    "            label_freq = None\n",
    "            if len(set(nodes.values())) == 2:\n",
    "                label_freq = {1: 0, 2: 0}\n",
    "            if len(set(nodes.values())) == 3:\n",
    "                label_freq = {1: 0, 2: 0, 3: 0}\n",
    "                \n",
    "            for l in label_freq.keys():\n",
    "                size = label_counter[node].labels.count(l)\n",
    "                if l not in minority_labels:\n",
    "                    size = round(size / float(threshold))\n",
    "                label_freq[l] = size\n",
    "\n",
    "            same_freq = len(set(label_freq.values())) == 1\n",
    "\n",
    "            # TODO function select update strategy\n",
    "            if unique_labels:\n",
    "                nodes[node] = label_counter[node].labels[0]\n",
    "                label_counter[node].unchanged_iter = 0\n",
    "            elif same_freq:\n",
    "                # TODO update unchanged state\n",
    "                label_counter[node].unchanged_iter += 1\n",
    "\n",
    "                if label_counter[node].unchanged_iter > 100:\n",
    "                    neighbors = G.neighbors(node)\n",
    "\n",
    "                    max_utility_score = -1\n",
    "                    node_label = None\n",
    "\n",
    "                    for neighbor_id in neighbors:\n",
    "                        neighbor = G.nodes[neighbor_id]\n",
    "                        if neighbor['utility_score'] > max_utility_score:\n",
    "                            max_utility_score = neighbor['utility_score']\n",
    "                            node_label = neighbor['label']\n",
    "\n",
    "                    nodes[node] = node_label\n",
    "                    label_counter[node].unchanged_iter = 0\n",
    "            else:\n",
    "                nodes[node] = max(label_freq.items(), key=operator.itemgetter(1))[0]\n",
    "                label_counter[node].unchanged_iter = 0\n",
    "\n",
    "            label_counter[node].labels = []\n",
    "            \n",
    "        new_labels = [value for (key, value) in nodes.items() if key not in known_nodes]\n",
    "        # print(old_labels)\n",
    "        # print(new_labels)\n",
    "        # print(list(nodes.values()).count(-1))\n",
    "        if (jaccard_score(old_labels, new_labels, average='micro') >= 0.99) & (-1 not in nodes.values()):\n",
    "            end = True\n",
    "        \n",
    "    return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collective_classification(G, df_features, pct, levels, df_positions, threshold, minority_labels):\n",
    "    feature_names = df_features.columns\n",
    "    \n",
    "    df_features = assign_management_levels(levels, df_features, df_positions)\n",
    "    \n",
    "    for utility_score_name in feature_names:\n",
    "        utility_score = df_features[[utility_score_name, POSITION]]     \n",
    "        known_nodes = select_nodes_based_on_utility_score(utility_score_name, utility_score, pct, levels)\n",
    "        \n",
    "        nx.set_node_attributes(G, -1, 'label')\n",
    "        nx.set_node_attributes(G, known_nodes, 'label')\n",
    "        nx.set_node_attributes(G, utility_score[utility_score_name], 'utility_score')\n",
    "        \n",
    "        nodes = message_passing(G, known_nodes, threshold, minority_labels)\n",
    "        # print(nodes)\n",
    "        nodes = pd.DataFrame.from_dict(nodes, orient='index', columns=[POSITION])\n",
    "        nodes.index.name = ID\n",
    "        \n",
    "        nodes = nodes.loc[~nodes.index.isin(known_nodes)]\n",
    "        \n",
    "        df_merged = pd.merge(nodes, df_features[POSITION], on=ID)\n",
    "        # print(df_merged)\n",
    "        f1 = f1_score(df_merged.iloc[:, 0], df_merged.iloc[:, 1], average='macro')\n",
    "        print('PCT: ', pct)\n",
    "        print('F1: ', f1)\n",
    "        print('Utiliti score: ', utility_score_name)\n",
    "        print('***********************************')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCT:  0.6\nF1:  0.8500000000000001\nUtiliti score:  in_degree\n***********************************\nPCT:  0.6\nF1:  0.6651162790697674\nUtiliti score:  out_degree\n***********************************\nPCT:  0.6\nF1:  0.7775718257645967\nUtiliti score:  betweenness\n***********************************\nPCT:  0.6\nF1:  0.4606741573033708\nUtiliti score:  closeness\n***********************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateusz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/Users/mateusz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCT:  0.6\nF1:  0.4606741573033708\nUtiliti score:  eigenvector\n***********************************\nPCT:  0.6\nF1:  0.1272727272727273\nUtiliti score:  clustering_coeff\n***********************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateusz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCT:  0.6\nF1:  0.7491289198606272\nUtiliti score:  pagerank\n***********************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateusz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCT:  0.6\nF1:  0.4606741573033708\nUtiliti score:  hubs\n***********************************\nPCT:  0.6\nF1:  0.8024691358024691\nUtiliti score:  authorities\n***********************************\nPCT:  0.6\nF1:  0.7433155080213902\nUtiliti score:  max_clique\n***********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCT:  0.6\nF1:  0.5909090909090909\nUtiliti score:  cliques_count\n***********************************\nPCT:  0.6\nF1:  0.4606741573033708\nUtiliti score:  overtime\n***********************************\nPCT:  0.6\nF1:  0.5909090909090909\nUtiliti score:  work_at_weekend\n***********************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateusz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCT:  0.6\nF1:  0.4606741573033708\nUtiliti score:  neighborhood_variability_sender\n***********************************\nPCT:  0.6\nF1:  0.6886005560704356\nUtiliti score:  neighborhood_variability_recipient\n***********************************\nPCT:  0.6\nF1:  0.4606741573033708\nUtiliti score:  neighborhood_variability_all\n***********************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateusz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/Users/mateusz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "collective_classification(G, df_features, pct=0.6, levels=2, df_positions=df_positions, threshold=3, minority_labels=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{80: 1, 10: 1, 50: 2, 40: 2, 90: 2}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_nodes_based_on_utility_score(BETWEENNESS, df, pct, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ID: [10,20,30,40,50,60,70,80,90,100], BETWEENNESS: [5,6,2,8,9,4,6,7,8,3], POSITION: [1,2,1,2,2,2,2,1,2,1]})\n",
    "df = df.set_index(ID)\n",
    "df_positions = pd.DataFrame({ID: [10,20,30,40,50,60,70,80,90,100], POSITION: [1,2,1,2,2,2,2,1,2,1]})\n",
    "pct = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, {80: 1, 10: 1, 50: 2, 40: 2, 90: 2}, 'asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(G.nodes(data='utility_score'), columns=[ID, 'utility_score'], index=ID).sort_values('utility_score', ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.round(2.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[81,\n 136,\n 156,\n 62,\n 16,\n 157,\n 116,\n 140,\n 28,\n 95,\n 17,\n 97,\n 132,\n 61,\n 121,\n 123,\n 119,\n 101,\n 85,\n 89,\n 152,\n 130,\n 155,\n 47,\n 166,\n 103,\n 133,\n 73,\n 8,\n 128,\n 112,\n 27,\n 83,\n 22,\n 108,\n 58,\n 52,\n 32,\n 3,\n 113,\n 150,\n 104,\n 78,\n 94,\n 74,\n 36,\n 45,\n 56,\n 50,\n 77,\n 64,\n 14,\n 37,\n 129,\n 105,\n 102,\n 144,\n 18,\n 66,\n 148,\n 137,\n 161,\n 60,\n 54,\n 91,\n 82,\n 86,\n 141,\n 69,\n 13,\n 19,\n 33,\n 107,\n 163,\n 98,\n 67,\n 135]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(G.neighbors(39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6453193150025995\n"
     ]
    }
   ],
   "source": [
    "neighbors = G.neighbors(77)\n",
    "\n",
    "max_utility_score = -1\n",
    "label = None\n",
    "\n",
    "for neighbor in neighbors:\n",
    "    node = G.nodes[neighbor]\n",
    "    if node['utility_score'] > max_utility_score:\n",
    "        max_utility_score = node['utility_score']\n",
    "        label = node['label']\n",
    "        \n",
    "print(label, max_utility_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {1: 5, 2: 8, 3: 7}\n",
    "hist = [1,1,2,2,2,2,2,2]\n",
    "threshold = 3\n",
    "minority_labels = [1]\n",
    "unique_labels = len(set(hist)) == 1\n",
    "levels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    }
   ],
   "source": [
    "count_1 = hist.count(1)\n",
    "count_2 = round(hist.count(2) / float(threshold))\n",
    "print(count_1, count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 2: 2}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_freq = None\n",
    "if levels == 2:\n",
    "    label_freq = {1: 0, 2: 0}\n",
    "if levels == 3:\n",
    "    label_freq = {1: 0, 2: 0, 3: 0}\n",
    "for l in label_freq.keys():\n",
    "    size = hist.count(l)\n",
    "    if l not in minority_labels:\n",
    "        size = round(size / float(threshold))\n",
    "    label_freq[l] = size\n",
    "same_freq = len(set(label_freq.values())) == 1\n",
    "label_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unchanged_iter\n"
     ]
    }
   ],
   "source": [
    "if count_1 > count_2:\n",
    "    print('if count_1 > count_2')\n",
    "elif count_2 > count_1:\n",
    "    print('if count_2 > count_1')\n",
    "elif unique_labels:\n",
    "    print('unique_labels')\n",
    "else:\n",
    "    print('unchanged_iter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unchanged_iter\n"
     ]
    }
   ],
   "source": [
    "if unique_labels:\n",
    "    print('unique_labels')\n",
    "elif same_freq:\n",
    "    print('unchanged_iter')\n",
    "else:\n",
    "    print(max(label_freq.items(), key=operator.itemgetter(1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nodes' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-cf92776e1c31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nodes' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "nodes['labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(label_freq.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
